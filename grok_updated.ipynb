{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c86f7f08-bd1b-47a0-8142-2f2fcd8d4a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/dill-0.3.9-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.14.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/opt_einsum-3.4.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.26a0+c5e1555-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "Collecting ccxt\n",
      "  Downloading ccxt-4.4.71-py2.py3-none-any.whl.metadata (131 kB)\n",
      "Requirement already satisfied: setuptools>=60.9.0 in /usr/local/lib/python3.12/dist-packages (from ccxt) (75.8.2)\n",
      "Requirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.12/dist-packages (from ccxt) (2025.1.31)\n",
      "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.12/dist-packages (from ccxt) (2.32.3)\n",
      "Collecting cryptography>=2.6.1 (from ccxt)\n",
      "  Downloading cryptography-44.0.2-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from ccxt) (4.12.2)\n",
      "INFO: pip is looking at multiple versions of ccxt to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting ccxt\n",
      "  Downloading ccxt-4.4.70-py2.py3-none-any.whl.metadata (131 kB)\n",
      "  Downloading ccxt-4.4.69-py2.py3-none-any.whl.metadata (131 kB)\n",
      "  Downloading ccxt-4.4.68-py2.py3-none-any.whl.metadata (131 kB)\n",
      "  Downloading ccxt-4.4.67-py2.py3-none-any.whl.metadata (131 kB)\n",
      "  Downloading ccxt-4.4.65-py2.py3-none-any.whl.metadata (129 kB)\n",
      "  Downloading ccxt-4.4.64-py2.py3-none-any.whl.metadata (130 kB)\n",
      "  Downloading ccxt-4.4.63-py2.py3-none-any.whl.metadata (130 kB)\n",
      "INFO: pip is still looking at multiple versions of ccxt to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading ccxt-4.4.62-py2.py3-none-any.whl.metadata (130 kB)\n",
      "  Downloading ccxt-4.4.61-py2.py3-none-any.whl.metadata (130 kB)\n",
      "  Downloading ccxt-4.4.60-py2.py3-none-any.whl.metadata (130 kB)\n",
      "  Downloading ccxt-4.4.59-py2.py3-none-any.whl.metadata (130 kB)\n",
      "  Downloading ccxt-4.4.58-py2.py3-none-any.whl.metadata (133 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading ccxt-4.4.57-py2.py3-none-any.whl.metadata (133 kB)\n",
      "  Downloading ccxt-4.4.53-py2.py3-none-any.whl.metadata (133 kB)\n",
      "  Downloading ccxt-4.4.52-py2.py3-none-any.whl.metadata (117 kB)\n",
      "  Downloading ccxt-4.4.51-py2.py3-none-any.whl.metadata (117 kB)\n",
      "  Downloading ccxt-4.4.50-py2.py3-none-any.whl.metadata (117 kB)\n",
      "  Downloading ccxt-4.4.49-py2.py3-none-any.whl.metadata (117 kB)\n",
      "  Downloading ccxt-4.4.48-py2.py3-none-any.whl.metadata (117 kB)\n",
      "  Downloading ccxt-4.4.47-py2.py3-none-any.whl.metadata (117 kB)\n",
      "  Downloading ccxt-4.4.46-py2.py3-none-any.whl.metadata (117 kB)\n",
      "  Downloading ccxt-4.4.45-py2.py3-none-any.whl.metadata (117 kB)\n",
      "  Downloading ccxt-4.4.44-py2.py3-none-any.whl.metadata (117 kB)\n",
      "  Downloading ccxt-4.4.43-py2.py3-none-any.whl.metadata (117 kB)\n",
      "  Downloading ccxt-4.4.42-py2.py3-none-any.whl.metadata (116 kB)\n",
      "  Downloading ccxt-4.4.41-py2.py3-none-any.whl.metadata (116 kB)\n",
      "  Downloading ccxt-4.4.40-py2.py3-none-any.whl.metadata (116 kB)\n",
      "  Downloading ccxt-4.4.39-py2.py3-none-any.whl.metadata (116 kB)\n",
      "  Downloading ccxt-4.4.38-py2.py3-none-any.whl.metadata (116 kB)\n",
      "  Downloading ccxt-4.4.37-py2.py3-none-any.whl.metadata (116 kB)\n",
      "  Downloading ccxt-4.4.36-py2.py3-none-any.whl.metadata (116 kB)\n",
      "  Downloading ccxt-4.4.35-py2.py3-none-any.whl.metadata (115 kB)\n",
      "  Downloading ccxt-4.4.34-py2.py3-none-any.whl.metadata (115 kB)\n",
      "  Downloading ccxt-4.4.33-py2.py3-none-any.whl.metadata (115 kB)\n",
      "  Downloading ccxt-4.4.32-py2.py3-none-any.whl.metadata (115 kB)\n",
      "  Downloading ccxt-4.4.31-py2.py3-none-any.whl.metadata (114 kB)\n",
      "  Downloading ccxt-4.4.30-py2.py3-none-any.whl.metadata (114 kB)\n",
      "Requirement already satisfied: aiohttp>=3.8 in /usr/local/lib/python3.12/dist-packages (from ccxt) (3.11.13)\n",
      "Collecting aiodns>=1.1.1 (from ccxt)\n",
      "  Downloading aiodns-3.2.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: yarl>=1.7.2 in /usr/local/lib/python3.12/dist-packages (from ccxt) (1.18.3)\n",
      "Collecting pycares>=4.0.0 (from aiodns>=1.1.1->ccxt)\n",
      "  Downloading pycares-4.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8->ccxt) (2.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8->ccxt) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8->ccxt) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8->ccxt) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8->ccxt) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8->ccxt) (0.3.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=2.6.1->ccxt) (1.17.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.18.4->ccxt) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.18.4->ccxt) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.18.4->ccxt) (2.0.7)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt) (2.22)\n",
      "Downloading ccxt-4.4.30-py2.py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiodns-3.2.0-py3-none-any.whl (5.7 kB)\n",
      "Downloading cryptography-44.0.2-cp39-abi3-manylinux_2_34_x86_64.whl (4.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pycares-4.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (289 kB)\n",
      "Installing collected packages: pycares, cryptography, aiodns, ccxt\n",
      "Successfully installed aiodns-3.2.0 ccxt-4.4.30 cryptography-44.0.2 pycares-4.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ccxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14a8b6f3-5fee-45c0-ae6b-d0d97448d524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружено 1000 свечей до 2018-01-30 16:00:00.001000\n",
      "Загружено 1000 свечей до 2018-07-18 00:00:00.001000\n",
      "Загружено 1000 свечей до 2018-12-31 20:00:00.001000\n",
      "Загружено 1000 свечей до 2019-06-17 00:00:00.001000\n",
      "Загружено 1000 свечей до 2019-11-30 20:00:00.001000\n",
      "Загружено 1000 свечей до 2020-05-15 16:00:00.001000\n",
      "Загружено 1000 свечей до 2020-10-29 08:00:00.001000\n",
      "Загружено 1000 свечей до 2021-04-14 00:00:00.001000\n",
      "Загружено 1000 свечей до 2021-09-27 16:00:00.001000\n",
      "Загружено 1000 свечей до 2022-03-13 08:00:00.001000\n",
      "Загружено 1000 свечей до 2022-08-27 00:00:00.001000\n",
      "Загружено 1000 свечей до 2023-02-09 16:00:00.001000\n",
      "Загружено 1000 свечей до 2023-07-26 08:00:00.001000\n",
      "Загружено 1000 свечей до 2024-01-09 00:00:00.001000\n",
      "Загружено 1000 свечей до 2024-06-23 16:00:00.001000\n",
      "Загружено 1000 свечей до 2024-12-07 08:00:00.001000\n",
      "Загружено 685 свечей до 2025-03-31 12:00:00.001000\n",
      "Данные сохранены в 'btc_usdt_4h_full.csv'. Всего строк: 16685\n"
     ]
    }
   ],
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Инициализация биржи\n",
    "exchange = ccxt.binance()\n",
    "symbol = 'BTC/USDT'\n",
    "timeframe = '4h'\n",
    "since = exchange.parse8601('2017-08-17T00:00:00Z')  # Самая ранняя дата для BTC/USDT на Binance\n",
    "\n",
    "# Список для хранения всех данных\n",
    "all_ohlcv = []\n",
    "\n",
    "# Текущая временная метка в миллисекундах\n",
    "current_time = int(time.time() * 1000)  # Текущая дата в миллисекундах\n",
    "\n",
    "# Ограничение на количество свечей за запрос (Binance обычно возвращает до 500 или 1000)\n",
    "limit = 1000\n",
    "\n",
    "# Загрузка данных с пагинацией\n",
    "while since < current_time:\n",
    "    try:\n",
    "        ohlcv = exchange.fetch_ohlcv(symbol, timeframe, since, limit)\n",
    "        if not ohlcv:\n",
    "            break  # Если данных больше нет, выходим\n",
    "        all_ohlcv.extend(ohlcv)\n",
    "        since = ohlcv[-1][0] + 1  # Обновляем since до следующей свечи\n",
    "        print(f\"Загружено {len(ohlcv)} свечей до {pd.to_datetime(since, unit='ms')}\")\n",
    "        time.sleep(1)  # Задержка, чтобы не превысить лимит запросов API\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка: {e}\")\n",
    "        break\n",
    "\n",
    "# Преобразование в DataFrame\n",
    "df = pd.DataFrame(all_ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "df.set_index('timestamp', inplace=True)\n",
    "\n",
    "# Удаление дубликатов, если есть\n",
    "df = df[~df.index.duplicated(keep='first')]\n",
    "\n",
    "# Сохранение в CSV\n",
    "df.to_csv('btc_usdt_4h_full.csv')\n",
    "print(f\"Данные сохранены в 'btc_usdt_4h_full.csv'. Всего строк: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9028186a-30d0-4001-b529-de4199a0fa64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/dill-0.3.9-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.14.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/opt_einsum-3.4.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.26a0+c5e1555-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "Collecting pandas_ta\n",
      "  Downloading pandas_ta-0.3.14b.tar.gz (115 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from pandas_ta) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas->pandas_ta) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->pandas_ta) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->pandas_ta) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->pandas_ta) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->pandas_ta) (1.16.0)\n",
      "Building wheels for collected packages: pandas_ta\n",
      "  Building wheel for pandas_ta (setup.py) ... \u001b[?25done\n",
      "\u001b[?25h  Created wheel for pandas_ta: filename=pandas_ta-0.3.14b0-py3-none-any.whl size=218986 sha256=325423a222ced5d6a12bd3c3bd31bd9b750c00b68f02ff47aa62fefc84f57a82\n",
      "  Stored in directory: /root/.cache/pip/wheels/fd/ed/18/2a12fd1b7906c63efca6accb351929f2c7f6bbc674e1c0ba5d\n",
      "Successfully built pandas_ta\n",
      "Installing collected packages: pandas_ta\n",
      "Successfully installed pandas_ta-0.3.14b0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pandas_ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb898fba-8398-45c6-a912-c0118520aa35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_157/429230575.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ebsw_result = ta.ebsw(df['close'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_csv('btc_usdt_4h_full.csv', index_col='timestamp', parse_dates=True)\n",
    "\n",
    "# Differencing\n",
    "for k in range(1, 6):\n",
    "    for col in ['open', 'high', 'low', 'close', 'volume']:\n",
    "        df[f'{col}_diff_{k}'] = df[col] / df[col].shift(k)\n",
    "\n",
    "# EBSW\n",
    "ebsw_result = ta.ebsw(df['close'])\n",
    "df['ebsw'] = ebsw_result\n",
    "\n",
    "# Chaikin Money Flow\n",
    "df['cmf'] = ta.cmf(df['high'], df['low'], df['close'], df['volume'], length=20)\n",
    "\n",
    "# VWAP\n",
    "df['tp'] = (df['low'] + df['high'] + df['close']) / 3\n",
    "df['vwap'] = (df['tp'] * df['volume']).cumsum() / df['volume'].cumsum()\n",
    "df['vwap_open'] = df['vwap'] / df['open']\n",
    "\n",
    "# Other Ratios\n",
    "df['high_low'] = df['high'] / df['low']\n",
    "df['high_open'] = df['high'] / df['open']\n",
    "df['close_open'] = df['close'] / df['open']\n",
    "df['low_open'] = df['low'] / df['open']\n",
    "\n",
    "# Time Information\n",
    "df['hour'] = df.index.hour\n",
    "df['day'] = df.index.day\n",
    "df['month'] = df.index.month\n",
    "\n",
    "# Удаляем строки с NaN\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df['high_next'] = df['high'].shift(-1)\n",
    "df['low_next'] = df['low'].shift(-1)\n",
    "df['u_t1'] = (df['high_next'] - df['close']) / df['close']\n",
    "df['v_t1'] = (df['low_next'] - df['close']) / df['close']\n",
    "\n",
    "def classify(u, v):\n",
    "    if u >= 0.0075:\n",
    "        return 0  # c0\n",
    "    elif v <= -0.0075:\n",
    "        return 1  # c1\n",
    "    else:\n",
    "        return 2  # c2\n",
    "\n",
    "df['target'] = [classify(u, v) for u, v in zip(df['u_t1'], df['v_t1'])]\n",
    "df.dropna(inplace=True)  # Удаляем последнюю строку\n",
    "\n",
    "# Сохранение обработанных данных\n",
    "df.to_csv('btc_usdt_4h_with_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eabbdb81-72c2-453b-9f66-d24db2a44bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_258/1382881761.py:10: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n",
      "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение y_train: [6147 2598  786]\n",
      "Распределение y_val: [167  88   9]\n",
      "Распределение y_test: [245 125  39]\n",
      "Веса классов: {0: 1.0, 1: 1.2, 2: 2.0}\n",
      "epoch 0  | loss: 2.00451 | val_0_accuracy: 0.54167 |  0:00:01s\n",
      "epoch 1  | loss: 1.13647 | val_0_accuracy: 0.54167 |  0:00:02s\n",
      "epoch 2  | loss: 1.07677 | val_0_accuracy: 0.5947  |  0:00:03s\n",
      "epoch 3  | loss: 1.08395 | val_0_accuracy: 0.56818 |  0:00:04s\n",
      "epoch 4  | loss: 0.99726 | val_0_accuracy: 0.61742 |  0:00:05s\n",
      "epoch 5  | loss: 1.01899 | val_0_accuracy: 0.60606 |  0:00:06s\n",
      "epoch 6  | loss: 1.00234 | val_0_accuracy: 0.56439 |  0:00:07s\n",
      "epoch 7  | loss: 1.00071 | val_0_accuracy: 0.57197 |  0:00:08s\n",
      "epoch 8  | loss: 0.97034 | val_0_accuracy: 0.5947  |  0:00:08s\n",
      "epoch 9  | loss: 0.96269 | val_0_accuracy: 0.52273 |  0:00:09s\n",
      "epoch 10 | loss: 0.99751 | val_0_accuracy: 0.61742 |  0:00:10s\n",
      "epoch 11 | loss: 0.93318 | val_0_accuracy: 0.60985 |  0:00:11s\n",
      "epoch 12 | loss: 0.93138 | val_0_accuracy: 0.64394 |  0:00:12s\n",
      "epoch 13 | loss: 0.90137 | val_0_accuracy: 0.57197 |  0:00:12s\n",
      "epoch 14 | loss: 0.89986 | val_0_accuracy: 0.60606 |  0:00:13s\n",
      "epoch 15 | loss: 0.9097  | val_0_accuracy: 0.63636 |  0:00:14s\n",
      "epoch 16 | loss: 0.9137  | val_0_accuracy: 0.61364 |  0:00:15s\n",
      "epoch 17 | loss: 0.90013 | val_0_accuracy: 0.61742 |  0:00:16s\n",
      "epoch 18 | loss: 0.89777 | val_0_accuracy: 0.63636 |  0:00:16s\n",
      "epoch 19 | loss: 0.88965 | val_0_accuracy: 0.62879 |  0:00:17s\n",
      "epoch 20 | loss: 0.87287 | val_0_accuracy: 0.62879 |  0:00:18s\n",
      "epoch 21 | loss: 0.8839  | val_0_accuracy: 0.64773 |  0:00:19s\n",
      "epoch 22 | loss: 0.86319 | val_0_accuracy: 0.64773 |  0:00:19s\n",
      "epoch 23 | loss: 0.86884 | val_0_accuracy: 0.63258 |  0:00:20s\n",
      "epoch 24 | loss: 0.86814 | val_0_accuracy: 0.625   |  0:00:21s\n",
      "epoch 25 | loss: 0.85098 | val_0_accuracy: 0.63258 |  0:00:22s\n",
      "epoch 26 | loss: 0.86258 | val_0_accuracy: 0.61364 |  0:00:22s\n",
      "epoch 27 | loss: 0.84363 | val_0_accuracy: 0.64015 |  0:00:23s\n",
      "epoch 28 | loss: 0.84347 | val_0_accuracy: 0.5947  |  0:00:24s\n",
      "epoch 29 | loss: 0.84166 | val_0_accuracy: 0.60606 |  0:00:25s\n",
      "epoch 30 | loss: 0.83774 | val_0_accuracy: 0.625   |  0:00:25s\n",
      "epoch 31 | loss: 0.8256  | val_0_accuracy: 0.64394 |  0:00:26s\n",
      "epoch 32 | loss: 0.83131 | val_0_accuracy: 0.63636 |  0:00:27s\n",
      "epoch 33 | loss: 0.83395 | val_0_accuracy: 0.64015 |  0:00:28s\n",
      "epoch 34 | loss: 0.82859 | val_0_accuracy: 0.62879 |  0:00:28s\n",
      "epoch 35 | loss: 0.84168 | val_0_accuracy: 0.61364 |  0:00:29s\n",
      "epoch 36 | loss: 0.82391 | val_0_accuracy: 0.62879 |  0:00:30s\n",
      "epoch 37 | loss: 0.82932 | val_0_accuracy: 0.625   |  0:00:31s\n",
      "epoch 38 | loss: 0.83004 | val_0_accuracy: 0.60606 |  0:00:31s\n",
      "epoch 39 | loss: 0.82784 | val_0_accuracy: 0.60606 |  0:00:32s\n",
      "epoch 40 | loss: 0.82934 | val_0_accuracy: 0.60227 |  0:00:33s\n",
      "epoch 41 | loss: 0.83134 | val_0_accuracy: 0.62121 |  0:00:34s\n",
      "epoch 42 | loss: 0.8073  | val_0_accuracy: 0.61364 |  0:00:35s\n",
      "epoch 43 | loss: 0.82    | val_0_accuracy: 0.61742 |  0:00:35s\n",
      "epoch 44 | loss: 0.82927 | val_0_accuracy: 0.63636 |  0:00:36s\n",
      "epoch 45 | loss: 0.82056 | val_0_accuracy: 0.63258 |  0:00:37s\n",
      "epoch 46 | loss: 0.8134  | val_0_accuracy: 0.64015 |  0:00:38s\n",
      "epoch 47 | loss: 0.81863 | val_0_accuracy: 0.64015 |  0:00:38s\n",
      "epoch 48 | loss: 0.8139  | val_0_accuracy: 0.64394 |  0:00:39s\n",
      "epoch 49 | loss: 0.82435 | val_0_accuracy: 0.62879 |  0:00:40s\n",
      "epoch 50 | loss: 0.81595 | val_0_accuracy: 0.62121 |  0:00:41s\n",
      "epoch 51 | loss: 0.81085 | val_0_accuracy: 0.62121 |  0:00:42s\n",
      "epoch 52 | loss: 0.81776 | val_0_accuracy: 0.62879 |  0:00:42s\n",
      "epoch 53 | loss: 0.80931 | val_0_accuracy: 0.63258 |  0:00:43s\n",
      "epoch 54 | loss: 0.81217 | val_0_accuracy: 0.63258 |  0:00:44s\n",
      "epoch 55 | loss: 0.80135 | val_0_accuracy: 0.62879 |  0:00:45s\n",
      "epoch 56 | loss: 0.81075 | val_0_accuracy: 0.62121 |  0:00:46s\n",
      "epoch 57 | loss: 0.80622 | val_0_accuracy: 0.625   |  0:00:46s\n",
      "epoch 58 | loss: 0.80574 | val_0_accuracy: 0.64015 |  0:00:47s\n",
      "epoch 59 | loss: 0.80242 | val_0_accuracy: 0.63258 |  0:00:48s\n",
      "epoch 60 | loss: 0.79976 | val_0_accuracy: 0.62121 |  0:00:49s\n",
      "epoch 61 | loss: 0.80819 | val_0_accuracy: 0.625   |  0:00:50s\n",
      "epoch 62 | loss: 0.80308 | val_0_accuracy: 0.63636 |  0:00:50s\n",
      "epoch 63 | loss: 0.80371 | val_0_accuracy: 0.62879 |  0:00:51s\n",
      "epoch 64 | loss: 0.80836 | val_0_accuracy: 0.62879 |  0:00:52s\n",
      "epoch 65 | loss: 0.79429 | val_0_accuracy: 0.64015 |  0:00:53s\n",
      "epoch 66 | loss: 0.78805 | val_0_accuracy: 0.62879 |  0:00:53s\n",
      "epoch 67 | loss: 0.80631 | val_0_accuracy: 0.62879 |  0:00:54s\n",
      "epoch 68 | loss: 0.80562 | val_0_accuracy: 0.63258 |  0:00:55s\n",
      "epoch 69 | loss: 0.80187 | val_0_accuracy: 0.63636 |  0:00:56s\n",
      "epoch 70 | loss: 0.79971 | val_0_accuracy: 0.65909 |  0:00:57s\n",
      "epoch 71 | loss: 0.79345 | val_0_accuracy: 0.625   |  0:00:57s\n",
      "epoch 72 | loss: 0.79643 | val_0_accuracy: 0.63636 |  0:00:58s\n",
      "epoch 73 | loss: 0.79583 | val_0_accuracy: 0.63258 |  0:00:59s\n",
      "epoch 74 | loss: 0.79887 | val_0_accuracy: 0.63258 |  0:01:00s\n",
      "epoch 75 | loss: 0.79425 | val_0_accuracy: 0.63636 |  0:01:01s\n",
      "epoch 76 | loss: 0.78364 | val_0_accuracy: 0.6553  |  0:01:01s\n",
      "epoch 77 | loss: 0.78059 | val_0_accuracy: 0.64394 |  0:01:02s\n",
      "epoch 78 | loss: 0.79022 | val_0_accuracy: 0.64015 |  0:01:03s\n",
      "epoch 79 | loss: 0.78433 | val_0_accuracy: 0.64015 |  0:01:04s\n",
      "epoch 80 | loss: 0.78059 | val_0_accuracy: 0.63636 |  0:01:04s\n",
      "epoch 81 | loss: 0.79601 | val_0_accuracy: 0.64394 |  0:01:05s\n",
      "epoch 82 | loss: 0.77735 | val_0_accuracy: 0.63636 |  0:01:06s\n",
      "epoch 83 | loss: 0.78267 | val_0_accuracy: 0.65152 |  0:01:07s\n",
      "epoch 84 | loss: 0.78254 | val_0_accuracy: 0.63636 |  0:01:07s\n",
      "epoch 85 | loss: 0.7871  | val_0_accuracy: 0.63258 |  0:01:08s\n",
      "epoch 86 | loss: 0.7824  | val_0_accuracy: 0.63258 |  0:01:09s\n",
      "epoch 87 | loss: 0.79207 | val_0_accuracy: 0.63258 |  0:01:09s\n",
      "epoch 88 | loss: 0.77877 | val_0_accuracy: 0.64394 |  0:01:10s\n",
      "epoch 89 | loss: 0.78741 | val_0_accuracy: 0.64015 |  0:01:11s\n",
      "epoch 90 | loss: 0.78298 | val_0_accuracy: 0.65152 |  0:01:12s\n",
      "epoch 91 | loss: 0.7893  | val_0_accuracy: 0.59848 |  0:01:13s\n",
      "epoch 92 | loss: 0.78141 | val_0_accuracy: 0.625   |  0:01:13s\n",
      "epoch 93 | loss: 0.78228 | val_0_accuracy: 0.62879 |  0:01:14s\n",
      "epoch 94 | loss: 0.78795 | val_0_accuracy: 0.63636 |  0:01:15s\n",
      "epoch 95 | loss: 0.79084 | val_0_accuracy: 0.63636 |  0:01:15s\n",
      "epoch 96 | loss: 0.77703 | val_0_accuracy: 0.64015 |  0:01:16s\n",
      "epoch 97 | loss: 0.78121 | val_0_accuracy: 0.625   |  0:01:18s\n",
      "epoch 98 | loss: 0.7889  | val_0_accuracy: 0.63636 |  0:01:18s\n",
      "epoch 99 | loss: 0.78675 | val_0_accuracy: 0.64015 |  0:01:19s\n",
      "epoch 100| loss: 0.77404 | val_0_accuracy: 0.63636 |  0:01:20s\n",
      "epoch 101| loss: 0.78411 | val_0_accuracy: 0.6553  |  0:01:21s\n",
      "epoch 102| loss: 0.77874 | val_0_accuracy: 0.63258 |  0:01:21s\n",
      "epoch 103| loss: 0.76927 | val_0_accuracy: 0.63636 |  0:01:22s\n",
      "epoch 104| loss: 0.77881 | val_0_accuracy: 0.63636 |  0:01:23s\n",
      "epoch 105| loss: 0.77066 | val_0_accuracy: 0.64394 |  0:01:24s\n",
      "epoch 106| loss: 0.77097 | val_0_accuracy: 0.66288 |  0:01:24s\n",
      "epoch 107| loss: 0.7779  | val_0_accuracy: 0.64773 |  0:01:25s\n",
      "epoch 108| loss: 0.76463 | val_0_accuracy: 0.63636 |  0:01:26s\n",
      "epoch 109| loss: 0.77371 | val_0_accuracy: 0.63258 |  0:01:27s\n",
      "epoch 110| loss: 0.77784 | val_0_accuracy: 0.6553  |  0:01:28s\n",
      "epoch 111| loss: 0.77087 | val_0_accuracy: 0.63636 |  0:01:28s\n",
      "epoch 112| loss: 0.76713 | val_0_accuracy: 0.62879 |  0:01:29s\n",
      "epoch 113| loss: 0.76385 | val_0_accuracy: 0.62879 |  0:01:30s\n",
      "epoch 114| loss: 0.77074 | val_0_accuracy: 0.63258 |  0:01:31s\n",
      "epoch 115| loss: 0.77241 | val_0_accuracy: 0.64394 |  0:01:31s\n",
      "epoch 116| loss: 0.78137 | val_0_accuracy: 0.63258 |  0:01:32s\n",
      "epoch 117| loss: 0.77457 | val_0_accuracy: 0.63258 |  0:01:33s\n",
      "epoch 118| loss: 0.78144 | val_0_accuracy: 0.63258 |  0:01:34s\n",
      "epoch 119| loss: 0.76632 | val_0_accuracy: 0.62879 |  0:01:34s\n",
      "epoch 120| loss: 0.7632  | val_0_accuracy: 0.63258 |  0:01:35s\n",
      "epoch 121| loss: 0.76937 | val_0_accuracy: 0.63636 |  0:01:36s\n",
      "epoch 122| loss: 0.77972 | val_0_accuracy: 0.63636 |  0:01:37s\n",
      "epoch 123| loss: 0.77967 | val_0_accuracy: 0.62879 |  0:01:37s\n",
      "epoch 124| loss: 0.76733 | val_0_accuracy: 0.625   |  0:01:38s\n",
      "epoch 125| loss: 0.76473 | val_0_accuracy: 0.63636 |  0:01:39s\n",
      "epoch 126| loss: 0.77251 | val_0_accuracy: 0.64015 |  0:01:40s\n",
      "epoch 127| loss: 0.77809 | val_0_accuracy: 0.63258 |  0:01:40s\n",
      "epoch 128| loss: 0.76889 | val_0_accuracy: 0.62879 |  0:01:41s\n",
      "epoch 129| loss: 0.76788 | val_0_accuracy: 0.63258 |  0:01:42s\n",
      "epoch 130| loss: 0.7752  | val_0_accuracy: 0.63258 |  0:01:43s\n",
      "epoch 131| loss: 0.76287 | val_0_accuracy: 0.63258 |  0:01:43s\n",
      "epoch 132| loss: 0.75352 | val_0_accuracy: 0.63258 |  0:01:44s\n",
      "epoch 133| loss: 0.7703  | val_0_accuracy: 0.62121 |  0:01:45s\n",
      "epoch 134| loss: 0.77695 | val_0_accuracy: 0.625   |  0:01:46s\n",
      "epoch 135| loss: 0.77278 | val_0_accuracy: 0.625   |  0:01:46s\n",
      "epoch 136| loss: 0.77519 | val_0_accuracy: 0.63258 |  0:01:47s\n",
      "epoch 137| loss: 0.76239 | val_0_accuracy: 0.63258 |  0:01:48s\n",
      "epoch 138| loss: 0.7688  | val_0_accuracy: 0.64773 |  0:01:49s\n",
      "epoch 139| loss: 0.77691 | val_0_accuracy: 0.64015 |  0:01:49s\n",
      "epoch 140| loss: 0.76903 | val_0_accuracy: 0.64394 |  0:01:50s\n",
      "epoch 141| loss: 0.7758  | val_0_accuracy: 0.62879 |  0:01:51s\n",
      "epoch 142| loss: 0.76247 | val_0_accuracy: 0.64394 |  0:01:52s\n",
      "epoch 143| loss: 0.76384 | val_0_accuracy: 0.63636 |  0:01:52s\n",
      "epoch 144| loss: 0.76576 | val_0_accuracy: 0.63258 |  0:01:53s\n",
      "epoch 145| loss: 0.7511  | val_0_accuracy: 0.64015 |  0:01:54s\n",
      "epoch 146| loss: 0.76336 | val_0_accuracy: 0.63636 |  0:01:55s\n",
      "epoch 147| loss: 0.76754 | val_0_accuracy: 0.63636 |  0:01:56s\n",
      "epoch 148| loss: 0.75346 | val_0_accuracy: 0.63258 |  0:01:56s\n",
      "epoch 149| loss: 0.76535 | val_0_accuracy: 0.63636 |  0:01:57s\n",
      "epoch 150| loss: 0.76588 | val_0_accuracy: 0.63636 |  0:01:58s\n",
      "epoch 151| loss: 0.76114 | val_0_accuracy: 0.62879 |  0:01:59s\n",
      "epoch 152| loss: 0.75502 | val_0_accuracy: 0.62121 |  0:01:59s\n",
      "epoch 153| loss: 0.75465 | val_0_accuracy: 0.62879 |  0:02:00s\n",
      "epoch 154| loss: 0.76912 | val_0_accuracy: 0.625   |  0:02:01s\n",
      "epoch 155| loss: 0.75384 | val_0_accuracy: 0.63636 |  0:02:02s\n",
      "epoch 156| loss: 0.77389 | val_0_accuracy: 0.61742 |  0:02:02s\n",
      "epoch 157| loss: 0.76278 | val_0_accuracy: 0.60606 |  0:02:03s\n",
      "epoch 158| loss: 0.76914 | val_0_accuracy: 0.63258 |  0:02:04s\n",
      "epoch 159| loss: 0.76739 | val_0_accuracy: 0.62879 |  0:02:05s\n",
      "epoch 160| loss: 0.76939 | val_0_accuracy: 0.60985 |  0:02:05s\n",
      "epoch 161| loss: 0.76745 | val_0_accuracy: 0.63258 |  0:02:06s\n",
      "epoch 162| loss: 0.76285 | val_0_accuracy: 0.625   |  0:02:07s\n",
      "epoch 163| loss: 0.76175 | val_0_accuracy: 0.62879 |  0:02:08s\n",
      "epoch 164| loss: 0.77054 | val_0_accuracy: 0.64015 |  0:02:08s\n",
      "epoch 165| loss: 0.76539 | val_0_accuracy: 0.61742 |  0:02:09s\n",
      "epoch 166| loss: 0.75823 | val_0_accuracy: 0.63258 |  0:02:10s\n",
      "epoch 167| loss: 0.76882 | val_0_accuracy: 0.60227 |  0:02:11s\n",
      "epoch 168| loss: 0.77936 | val_0_accuracy: 0.63258 |  0:02:11s\n",
      "epoch 169| loss: 0.7668  | val_0_accuracy: 0.60606 |  0:02:12s\n",
      "epoch 170| loss: 0.77418 | val_0_accuracy: 0.60606 |  0:02:13s\n",
      "epoch 171| loss: 0.76921 | val_0_accuracy: 0.61364 |  0:02:14s\n",
      "epoch 172| loss: 0.76773 | val_0_accuracy: 0.625   |  0:02:15s\n",
      "epoch 173| loss: 0.76798 | val_0_accuracy: 0.61742 |  0:02:15s\n",
      "epoch 174| loss: 0.76885 | val_0_accuracy: 0.60606 |  0:02:16s\n",
      "epoch 175| loss: 0.77925 | val_0_accuracy: 0.61364 |  0:02:17s\n",
      "epoch 176| loss: 0.76811 | val_0_accuracy: 0.58333 |  0:02:18s\n",
      "epoch 177| loss: 0.76994 | val_0_accuracy: 0.62879 |  0:02:18s\n",
      "epoch 178| loss: 0.7667  | val_0_accuracy: 0.59091 |  0:02:19s\n",
      "epoch 179| loss: 0.76135 | val_0_accuracy: 0.59848 |  0:02:20s\n",
      "epoch 180| loss: 0.76204 | val_0_accuracy: 0.625   |  0:02:21s\n",
      "epoch 181| loss: 0.74299 | val_0_accuracy: 0.625   |  0:02:22s\n",
      "epoch 182| loss: 0.76202 | val_0_accuracy: 0.62121 |  0:02:22s\n",
      "epoch 183| loss: 0.75491 | val_0_accuracy: 0.62121 |  0:02:23s\n",
      "epoch 184| loss: 0.76404 | val_0_accuracy: 0.61742 |  0:02:24s\n",
      "epoch 185| loss: 0.76024 | val_0_accuracy: 0.60985 |  0:02:24s\n",
      "epoch 186| loss: 0.75162 | val_0_accuracy: 0.62121 |  0:02:25s\n",
      "epoch 187| loss: 0.75285 | val_0_accuracy: 0.61742 |  0:02:26s\n",
      "epoch 188| loss: 0.7713  | val_0_accuracy: 0.61742 |  0:02:27s\n",
      "epoch 189| loss: 0.7608  | val_0_accuracy: 0.62879 |  0:02:28s\n",
      "epoch 190| loss: 0.76393 | val_0_accuracy: 0.62879 |  0:02:28s\n",
      "epoch 191| loss: 0.75114 | val_0_accuracy: 0.65152 |  0:02:29s\n",
      "epoch 192| loss: 0.75921 | val_0_accuracy: 0.61742 |  0:02:30s\n",
      "epoch 193| loss: 0.76059 | val_0_accuracy: 0.63636 |  0:02:31s\n",
      "epoch 194| loss: 0.7549  | val_0_accuracy: 0.60985 |  0:02:31s\n",
      "epoch 195| loss: 0.75193 | val_0_accuracy: 0.62121 |  0:02:32s\n",
      "epoch 196| loss: 0.75324 | val_0_accuracy: 0.61742 |  0:02:33s\n",
      "epoch 197| loss: 0.76324 | val_0_accuracy: 0.64015 |  0:02:34s\n",
      "epoch 198| loss: 0.76455 | val_0_accuracy: 0.64015 |  0:02:34s\n",
      "epoch 199| loss: 0.76286 | val_0_accuracy: 0.64394 |  0:02:35s\n",
      "epoch 200| loss: 0.75384 | val_0_accuracy: 0.64015 |  0:02:36s\n",
      "epoch 201| loss: 0.76348 | val_0_accuracy: 0.63636 |  0:02:37s\n",
      "epoch 202| loss: 0.75708 | val_0_accuracy: 0.63636 |  0:02:37s\n",
      "epoch 203| loss: 0.7509  | val_0_accuracy: 0.64773 |  0:02:38s\n",
      "epoch 204| loss: 0.75798 | val_0_accuracy: 0.625   |  0:02:39s\n",
      "epoch 205| loss: 0.75066 | val_0_accuracy: 0.64015 |  0:02:40s\n",
      "epoch 206| loss: 0.75498 | val_0_accuracy: 0.64015 |  0:02:40s\n",
      "\n",
      "Early stopping occurred at epoch 206 with best_epoch = 106 and best_val_0_accuracy = 0.66288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение предсказанных классов: [395  14]\n",
      "Распределение истинных классов: [245 125  39]\n",
      "Accuracy: 0.5892\n",
      "F1-score: 0.4638\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          c0       0.60      0.96      0.74       245\n",
      "          c1       0.36      0.04      0.07       125\n",
      "          c2       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.59       409\n",
      "   macro avg       0.32      0.33      0.27       409\n",
      "weighted avg       0.47      0.59      0.46       409\n",
      "\n",
      "\n",
      "Топ-5 важных признаков:\n",
      " high_low        0.148183\n",
      "atr             0.117177\n",
      "close_diff_1    0.093142\n",
      "open_diff_1     0.088827\n",
      "close_open      0.067836\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import pandas_ta as ta\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Загрузка и обработка данных\n",
    "df = pd.read_csv('btc_usdt_4h_with_target.csv', index_col='timestamp', parse_dates=True)\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Пересчет целевой переменной с новым порогом\n",
    "df['high_next'] = df['high'].shift(-1)\n",
    "df['low_next'] = df['low'].shift(-1)\n",
    "df['u_t1'] = (df['high_next'] - df['close']) / df['close']\n",
    "df['v_t1'] = (df['low_next'] - df['close']) / df['close']\n",
    "threshold = 0.005\n",
    "df['target'] = np.where(df['u_t1'] >= threshold, 0, np.where(df['v_t1'] <= -threshold, 1, 2))\n",
    "\n",
    "# Добавление ATR\n",
    "def calculate_atr(df, period=14):\n",
    "    df['tr'] = np.maximum(df['high'] - df['low'], \n",
    "                         np.maximum(abs(df['high'] - df['close'].shift(1)), \n",
    "                                    abs(df['low'] - df['close'].shift(1))))\n",
    "    df['atr'] = df['tr'].rolling(window=period).mean()\n",
    "    return df\n",
    "\n",
    "df = calculate_atr(df)\n",
    "df['cmf'] = ta.cmf(df['high'], df['low'], df['close'], df['volume'], length=20)\n",
    "df['vwap'] = ta.vwap(df['high'], df['low'], df['close'], df['volume'])\n",
    "df['vwap_open'] = df['vwap'] / df['open']\n",
    "\n",
    "# Разделение данных\n",
    "train_df = df['2017-08-23 16:00:00':'2021-12-31 16:00:00']\n",
    "val_df = df['2022-01-01 00:00:00':'2022-02-13 20:00:00']\n",
    "test_df = df['2022-02-14 00:00:00':'2022-04-23 00:00:00']\n",
    "\n",
    "# Ограничение признаков\n",
    "key_features = ['open', 'high', 'low', 'close', 'volume', 'close_open', 'high_low', \n",
    "                'open_diff_1', 'open_diff_2', 'close_diff_1', 'close_diff_2', \n",
    "                'volume_diff_1', 'volume_diff_2', 'cmf', 'vwap_open', 'atr']\n",
    "features = [col for col in df.columns if col in key_features]\n",
    "X_train = train_df[features].values\n",
    "y_train = train_df['target'].values\n",
    "X_val = val_df[features].values\n",
    "y_val = val_df['target'].values\n",
    "X_test = test_df[features].values\n",
    "y_test = test_df['target'].values\n",
    "\n",
    "# Обработка inf\n",
    "for i, col in enumerate(features):\n",
    "    max_val = np.percentile(df[col][~np.isinf(df[col])], 99)\n",
    "    min_val = np.percentile(df[col][~np.isinf(df[col])], 1)\n",
    "    X_train[:, i] = np.where(np.isinf(X_train[:, i]), max_val, X_train[:, i])\n",
    "    X_val[:, i] = np.where(np.isinf(X_val[:, i]), max_val, X_val[:, i])\n",
    "    X_test[:, i] = np.where(np.isinf(X_test[:, i]), max_val, X_test[:, i])\n",
    "X_train = np.nan_to_num(X_train, nan=0.0)\n",
    "X_val = np.nan_to_num(X_val, nan=0.0)\n",
    "X_test = np.nan_to_num(X_test, nan=0.0)\n",
    "\n",
    "# Нормализация и шум\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train) + np.random.normal(0, 0.005, X_train.shape)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Проверка распределения\n",
    "print(\"Распределение y_train:\", np.bincount(y_train))\n",
    "print(\"Распределение y_val:\", np.bincount(y_val))\n",
    "print(\"Распределение y_test:\", np.bincount(y_test))\n",
    "\n",
    "# Веса классов\n",
    "class_weights_dict = {0: 1.0, 1: 1.2, 2: 2.0}\n",
    "print(\"Веса классов:\", class_weights_dict)\n",
    "\n",
    "# Инициализация и обучение TabNet\n",
    "clf = TabNetClassifier(\n",
    "    n_d=128, n_a=128, n_steps=5, gamma=1.5,\n",
    "    lambda_sparse=0.005, optimizer_params=dict(lr=1e-3, weight_decay=1e-5),\n",
    "    mask_type='sparsemax', n_shared=2,\n",
    "    verbose=1, seed=42\n",
    ")\n",
    "clf.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric=['accuracy'],\n",
    "    max_epochs=300,\n",
    "    patience=100,\n",
    "    batch_size=512,\n",
    "    virtual_batch_size=256,\n",
    "    weights=class_weights_dict,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "# Предсказание и оценка\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Распределение предсказанных классов:\", np.bincount(y_pred))\n",
    "print(\"Распределение истинных классов:\", np.bincount(y_test))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=['c0', 'c1', 'c2']))\n",
    "\n",
    "# Важность признаков\n",
    "feature_importances = pd.Series(clf.feature_importances_, index=features)\n",
    "print(\"\\nТоп-5 важных признаков:\\n\", feature_importances.sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158c0923-8337-4920-b93a-cc49b408b1ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
